{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 100\n",
    "ROI_left = 350\n",
    "\n",
    "# img dimensions\n",
    "SIZE = (28, 28)\n",
    "CLASSES = dict(zip(range(0, 26), list(map(chr, range(97, 123))))) # labels from A to Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    diff = cv.absdiff(background.astype(\"uint8\"), frame)\n",
    "    \n",
    "    _ , thresholded = cv.threshold(diff, threshold, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "     # Fetching contours in the frame (These contours can be of hand or any other object in foreground) image, \n",
    "    contours, hierarchy = cv.findContours(thresholded.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # If length of contours list = 0, means we didn't get any contours...\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # The largest external contour should be the hand \n",
    "        hand_segment_max_cont = max(contours, key=cv.contourArea)\n",
    "        \n",
    "        # Returning the hand segment(max contour) and the\n",
    "        # thresholded image of hand...\n",
    "        return (thresholded, hand_segment_max_cont)\n",
    "\n",
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "    global background\n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data-flair.training/blogs/sign-language-recognition-python-ml-opencv/\n",
    "\n",
    "cam = cv.VideoCapture(0)\n",
    "num_frames =0\n",
    "start = False\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    # flipping the frame to prevent inverted image of captured frame\n",
    "    frame = cv.flip(frame, 1)\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "    gray_frame = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    # gray_frame = cv.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "    if num_frames < 70:\n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        cv.putText(frame_copy, \"FETCHING BACKGROUND. PLEASE WAIT\", (80, 400), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            thresholded, hand_segment = hand\n",
    "            # Drawing contours around hand segment\n",
    "            cv.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            # thresholded = np.array(thresholded)\n",
    "            thresholded = cv.resize(thresholded, SIZE)\n",
    "            # thresholded = np.reshape(thresholded, (1,thresholded.shape[0],thresholded.shape[1]))\n",
    "            # thresholded = cv.cvtColor(thresholded, cv.COLOR_GRAY2RGB)\n",
    "            # img = cv.cvtColor(thresholded, cv.COLOR_RGB2GRAY)\n",
    "            \n",
    "            if start:\n",
    "                print(thresholded.shape)\n",
    "                try:\n",
    "                    pred = model.predict(thresholded)\n",
    "                    print(CLASSES[np.argmax(pred)])\n",
    "                except ValueError:\n",
    "                    print(\"Error\")\n",
    "                    pass\n",
    "            # cv.putText(frame_copy, CLASSES[np.argmax(pred)], (170, 45), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right, ROI_bottom), (255,128,0), 3)\n",
    "    \n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    k = cv.waitKey(1)\n",
    "    if k == ord('a'):\n",
    "        start = not start\n",
    "\n",
    "    cv.putText(frame_copy, \"Hand ROI\",\n",
    "    (10, 20), cv.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv.imshow(\"Sign Detection\", frame_copy)\n",
    "    \n",
    "    # Close windows with Esc\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "start = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        # reverse the frame because of the camera orientation\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame_copy = frame[100:400, 100:400]\n",
    "\n",
    "        if start:\n",
    "            region_of_interest = np.array(frame_copy)  # get the frame\n",
    "            img = cv.cvtColor(region_of_interest, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "            # resize the image to 28x28\n",
    "            img = cv.resize(img, SIZE)\n",
    "            # prediction = get_predicted_class(model, img)\n",
    "            \n",
    "            # print(prediction)\n",
    "            start = False\n",
    "\n",
    "        cv.rectangle(frame_copy, (100,400), (100,400), (255,128,0), 3)\n",
    "        cv.imshow(\"Collecting images\", frame)\n",
    "\n",
    "        k = cv.waitKey(10)\n",
    "        if k == ord('a'):\n",
    "            start = not start\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"[ERR] {e}\")\n",
    "    pass\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# load image using opencv and make prediction\n",
    "img = cv.imread('a.jpg')\n",
    "# resize the image to 28x28\n",
    "img = cv.resize(img, SIZE)\n",
    "img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "img = np.array(img)\n",
    "img = np.reshape(img, (28,28))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.60392157, 0.37254902, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        0.79607843, 0.61176471, 0.70980392, 0.23921569, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.71372549, 0.78431373, 0.63529412,\n",
       "        0.80784314, 0.69411765, 0.38823529, 0.50980392, 0.89803922,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.64313725, 0.77254902, 0.74901961, 0.37254902, 0.72156863,\n",
       "        0.35294118, 0.68627451, 0.03137255, 0.68235294, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.69019608,\n",
       "        0.76078431, 0.58823529, 0.76078431, 0.5372549 , 0.80392157,\n",
       "        0.31764706, 0.62745098, 0.04705882, 0.63921569, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.65882353,\n",
       "        0.76078431, 0.68627451, 0.84705882, 0.64313725, 0.84313725,\n",
       "        0.57254902, 0.58823529, 0.1254902 , 0.62352941, 0.99607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.8627451 ,\n",
       "        0.6627451 , 0.75294118, 0.61568627, 0.65882353, 0.67843137,\n",
       "        0.36862745, 0.62745098, 0.39215686, 0.52941176, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.79215686,\n",
       "        0.5372549 , 0.55294118, 0.16078431, 0.48235294, 0.54901961,\n",
       "        0.36078431, 0.77647059, 0.48627451, 0.33333333, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.81568627,\n",
       "        0.8       , 0.59215686, 0.54509804, 0.66666667, 0.76470588,\n",
       "        0.74901961, 0.69803922, 0.36470588, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.74901961,\n",
       "        0.83137255, 0.69803922, 0.67058824, 0.79607843, 0.82352941,\n",
       "        0.72156863, 0.56470588, 0.32941176, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.69019608,\n",
       "        0.77254902, 0.80392157, 0.68235294, 0.69019608, 0.65882353,\n",
       "        0.61176471, 0.39607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.8       ,\n",
       "        0.67843137, 0.6627451 , 0.61568627, 0.63921569, 0.51372549,\n",
       "        0.42352941, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.6627451 ,\n",
       "        0.56862745, 0.61568627, 0.65098039, 0.60784314, 0.36862745,\n",
       "        0.67843137, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.69019608, 0.68627451, 0.65882353, 0.45490196, 0.36078431,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img/255.0\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2497aba0d00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANI0lEQVR4nO3dX4xc9XnG8ecpxAgcXxi8NgZbbByBVATUiRarElVEFWoMN8YIV1kky5UQzgVIiZSLovQi3IGqJlGFqoBTTEwViAKJsYVQG2RFMrkgeAAX7FqwBrbx2ou9xoJgMArGby/2UC1m5zfrmTN/wvv9SKOZOe+cPa9H+/icOb85+3NECMAX31/0uwEAvUHYgSQIO5AEYQeSIOxAEuf2cmOLFi2K4eHhXm4SSGV8fFzHjh3zbLWOwm57jaR/lXSOpH+PiPtLrx8eHlaj0ehkkwAKRkZGmtbaPoy3fY6kf5N0k6QrJY3avrLdnweguzr5zL5K0oGIeDMi/iTpF5LW1tMWgLp1EvZLJR2c8XyiWvYZtjfZbthuTE1NdbA5AJ3oJOyznQT43HdvI2JzRIxExMjQ0FAHmwPQiU7CPiFp+YznyyQd7qwdAN3SSdh3S7rc9ldsz5P0LUk76mkLQN3aHnqLiFO275b0X5oeetsSEftq6wxArToaZ4+IZyQ9U1MvALqIr8sCSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuhoymbb45Lel/SJpFMRMVJHUwDq11HYK38bEcdq+DkAuojDeCCJTsMekn5j+0Xbm2Z7ge1Nthu2G1NTUx1uDkC7Og37dRHxdUk3SbrL9jfOfEFEbI6IkYgYGRoa6nBzANrVUdgj4nB1f1TSNkmr6mgKQP3aDrvt+bYXfPpY0mpJe+tqDEC9Ojkbv0TSNtuf/pzHIuI/a+kKQO3aDntEvCnpr2rsBUAXMfQGJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJ1TOwItOXBBx8s1nft2lWsP/bYY3W284XHnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUURUaw3Go1i/eWXX25aW7ZsWXHdN954o1jH2Wm5Z7e9xfZR23tnLLvQ9rO2x6r7hd1tE0Cn5nIY/zNJa85Ydo+knRFxuaSd1XMAA6xl2CNil6TjZyxeK2lr9XirpFvqbQtA3do9QbckIiYlqbpf3OyFtjfZbthuTE1Ntbk5AJ3q+tn4iNgcESMRMTI0NNTtzQFoot2wH7G9VJKq+6P1tQSgG9oN+w5JG6vHGyVtr6cdAN3Scpzd9uOSrpe0yPaEpB9Iul/SL23fIekPktZ3s0m07+mnny7WL7roomL9tddeK9avueaaYn3x4qanc/TEE08U112z5sxBoM86fPhwsX7JJZcU69m0DHtEjDYpfbPmXgB0EV+XBZIg7EAShB1IgrADSRB2IAkucf0z8OijjxbrK1asaFq74IILius+8MADxfqGDRuK9fvuu69YHx1tNpjT+t/15JNPFusMrZ0d9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7ANg27Ztxfpll11WrO/Zs6dp7eqrry6ue9VVVxXrpUtUJenkyZPF+rvvvtu0du655V+/EydOFOs4O+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkHQKux6lZK13UvWbKkuG6raZNbXQ9/ww03FOsffvhh09qiRYuK6546dapYbzWdtO1iPRv27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsA2DVqlXF+u7du4v1iy++uGntueeeK647f/78Yn3fvn3F+gsvvFCsl8bhb7zxxuK6k5OTxTrj6Gen5Z7d9hbbR23vnbHsXtuHbO+pbjd3t00AnZrLYfzPJK2ZZfmPI2JldXum3rYA1K1l2CNil6TjPegFQBd1coLubtuvVIf5C5u9yPYm2w3bjampqQ42B6AT7Yb9J5K+KmmlpElJP2z2wojYHBEjETEyNDTU5uYAdKqtsEfEkYj4JCJOS/qppPLpZAB911bYbS+d8XSdpL3NXgtgMLQcZ7f9uKTrJS2yPSHpB5Kut71SUkgal/Tt7rX4xXf8ePn851tvvVWsHzx4sGntoYceKq67fv36Yn3hwqanYyRJp0+fLtavuOKKprWxsbHiuo1Go1jH2WkZ9ogYnWXxw13oBUAX8XVZIAnCDiRB2IEkCDuQBGEHkuAS1wEwb968Yn316tXF+vPPP9+0dueddxbXHR4eLtZLf6Zakq699tpi/Z133mlaGx8fL6771FNPFes4O+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkHQKtLXBcvXlysL1++vGnto48+Kq67YsWKYv28884r1g8dOlSsHzhwoGmtNJ0z6seeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJx9ALz33nvFeqvr3ZctW9a01uqa8YmJiWL95MmTxfqJEyeK9b17m08psH379uK6qBd7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2AVC6Hl1qPVb+8ccfN621GgdvNYbfarrot99+u1h/5JFHinX0Tss9u+3ltn9re7/tfba/Uy2/0Paztseq+/JE3gD6ai6H8ackfS8i/lLSX0u6y/aVku6RtDMiLpe0s3oOYEC1DHtETEbES9Xj9yXtl3SppLWStlYv2yrpli71CKAGZ3WCzvawpK9J+r2kJRExKU3/hyBp1j+UZnuT7YbtxtTUVIftAmjXnMNu+8uSfiXpuxHxx7muFxGbI2IkIkaGhoba6RFADeYUdttf0nTQfx4Rv64WH7G9tKovlXS0Oy0CqEPLoTfblvSwpP0R8aMZpR2SNkq6v7rnesU2jY2NFeuTk5PF+oIFC5rWzj///OK6H3zwQbH++uuvF+u33nprsY7BMZdx9uskbZD0qu091bLvazrkv7R9h6Q/SFrflQ4B1KJl2CPid5LcpPzNetsB0C18XRZIgrADSRB2IAnCDiRB2IEkuMR1AIyOjhbr27ZtK9Yjommt1ZTN+/fvL9ZPnz5drN92223FOgYHe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9j8D69at69rPvv3227v2szFY2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEi3Dbnu57d/a3m97n+3vVMvvtX3I9p7qdnP32wXQrrn88YpTkr4XES/ZXiDpRdvPVrUfR8S/dK89AHWZy/zsk5Imq8fv294v6dJuNwagXmf1md32sKSvSfp9tehu26/Y3mJ7YZN1Ntlu2G5MTU111i2Ats057La/LOlXkr4bEX+U9BNJX5W0UtN7/h/Otl5EbI6IkYgYGRoa6rxjAG2ZU9htf0nTQf95RPxakiLiSER8EhGnJf1U0qrutQmgU3M5G29JD0vaHxE/mrF86YyXrZO0t/72ANRlLmfjr5O0QdKrtvdUy74vadT2SkkhaVzSt7vQH4CazOVs/O8keZbSM/W3A6Bb+AYdkARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCUdE7zZmT0n63xmLFkk61rMGzs6g9jaofUn01q46e7ssImb9+289DfvnNm43ImKkbw0UDGpvg9qXRG/t6lVvHMYDSRB2IIl+h31zn7dfMqi9DWpfEr21qye99fUzO4De6feeHUCPEHYgib6E3fYa26/ZPmD7nn700IztcduvVtNQN/rcyxbbR23vnbHsQtvP2h6r7medY69PvQ3ENN6Facb7+t71e/rznn9mt32OpNcl/Z2kCUm7JY1GxP/0tJEmbI9LGomIvn8Bw/Y3JJ2Q9GhEXFUt+2dJxyPi/uo/yoUR8Y8D0tu9kk70exrvaraipTOnGZd0i6R/UB/fu0Jff68evG/92LOvknQgIt6MiD9J+oWktX3oY+BFxC5Jx89YvFbS1urxVk3/svRck94GQkRMRsRL1eP3JX06zXhf37tCXz3Rj7BfKungjOcTGqz53kPSb2y/aHtTv5uZxZKImJSmf3kkLe5zP2dqOY13L50xzfjAvHftTH/eqX6EfbappAZp/O+6iPi6pJsk3VUdrmJu5jSNd6/MMs34QGh3+vNO9SPsE5KWz3i+TNLhPvQxq4g4XN0flbRNgzcV9ZFPZ9Ct7o/2uZ//N0jTeM82zbgG4L3r5/Tn/Qj7bkmX2/6K7XmSviVpRx/6+Bzb86sTJ7I9X9JqDd5U1Dskbaweb5S0vY+9fMagTOPdbJpx9fm96/v05xHR85ukmzV9Rv4NSf/Ujx6a9LVC0n9Xt3397k3S45o+rPtY00dEd0i6SNJOSWPV/YUD1Nt/SHpV0iuaDtbSPvX2N5r+aPiKpD3V7eZ+v3eFvnryvvF1WSAJvkEHJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n8H1mSB0/My0/qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show image\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_2_input'), name='flatten_2_input', description=\"created by layer 'flatten_2_input'\"), but it was called on an input with incompatible shape (None, 28).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n    \n    Input 0 of layer \"dense_4\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 28)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 28), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8088/2816782044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n    \n    Input 0 of layer \"dense_4\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 28)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 28), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img)\n",
    "print(CLASSES[np.argmax(prediction)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ce70e7fb09d93846fb9da31c8ffeaa9e6be9e848f96b1b1e309019ff423a0ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
